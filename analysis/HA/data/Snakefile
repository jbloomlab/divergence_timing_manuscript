"""
Pipeline for prepping HA sequences for `phydms`

SKH 20171217
"""

from Bio import SeqIO
import re
import random
import os
import pandas as pd
import glob
import scipy
from pymodules.utils import *
from collections import Counter

# Set up for translation and pairwise
# codon to index, add codon `---`
max_codon_index = (max(list(constants.CODON_TO_INDEX.values())))
if "---" not in list(constants.CODON_TO_INDEX.keys()):
    constants.CODON_TO_INDEX["---"] = max_codon_index + 1
# index to AA, add AA `-`
max_AA_index = max(list(constants.INDEX_TO_AA.keys()))
if "-" not in list(constants.INDEX_TO_AA.values()):
    constants.INDEX_TO_AA[max_AA_index+1] = "-"
# condon to AA, add mapping of `---` to `-`
constants.CODON_TO_AA = scipy.append(constants.CODON_TO_AA, [[max_AA_index+1]])

# Globals ---------------------------------------------------------------------

# HA subtypes to include in the analysis
NUMBERS = [x for x in range(1, 19) if x not in [12, 15, 17, 18]]

# reference sequence names and headers
WSN_REF = "references/WSN_HA_reference.fasta"
WSN_REF_HEADER = "Reference_WSN_HA_coding_sequence_noStart_noStop"
PERTH_REF = "references/Perth_HA_reference.fasta"
PERTH_REF_HEADER = "Reference_Perth2009_HA_coding_sequence_noStop"
HYBRID_REF = "references/WSN_hybrid_reference.fasta"
HYBRID_REF_HEADER = "WSN_hybrid_nt"

# Reference strains
STRAINS = ["hybrid"]

# Divergence levels for the subsamples
LEVEL_NAMES = ["lowH1", "intermediateH1", "lowH3", "intermediateH3"]
LEVELS = [[1, 2, 5, 6], [1, 2, 5, 6, 8, 9, 11, 13, 16],
          [3, 4, 14], [3, 4, 14, 10, 7]]
assert len(LEVEL_NAMES) == len(set(LEVEL_NAMES))
assert len(LEVEL_NAMES) == len(LEVELS)

LEVEL_NAMES.append("high")
LEVELS.append(NUMBERS)

# Number of subsampled alignments
SEEDS = range(1)
# Rules -----------------------------------------------------------------------

rule all:
    input:
        "subsample/divergence_distances.csv",

# Add in each reference sequence to each set of HA sequences (next 3 rules)
rule add_in_WSN:
    """
    `phydms_prepalignment` requires the DMS reference sequence to be present in
    the `inseqs` file. This function adds in the WSN reference from the Doud
    DMS.
    """
    message: "Add in WSN reference to the files"
    input:
        fasta = "raw/all_H{number}.fasta"
    output:
        temp_file = "_temp_WSN_{number}.fasta"
    shell:
        'cat {input.fasta} {WSN_REF} > {output.temp_file}'

rule add_in_Perth:
    """
    `phydms_prepalignment` requires the DMS reference sequence to be present in
    the `inseqs` file. This function adds in the Perth reference from the Lee
    DMS.
    """
    message: "Add in Perth reference to the files"
    input:
        fasta = "raw/all_H{number}.fasta"
    output:
        temp_file = "_temp_Perth_{number}.fasta"
    shell:
        'cat {input.fasta} {PERTH_REF} > {output.temp_file}'

rule add_in_hybrid:
    """
    `phydms_prepalignment` requires the DMS reference sequence to be present in
    the `inseqs` file. This function adds in the "hybrid" sequence for
    analysis with the average preferences.
    """
    message: "Add in hybrid reference to the files"
    input:
        fasta = "raw/all_H{number}.fasta"
    output:
        temp_file = "_temp_hybrid_{number}.fasta"
    shell:
        'cat {input.fasta} {HYBRID_REF} > {output.temp_file}'

# Run `phydms_prepalignment` for each of the set of HA sequences (next 3 rules)
rule phydms_prepalignment_WSN:
    """
    `phydms_prepalignment` QC's the data and makes an alignment using `mafft`.
    """
    message: "Running `phydms_prepalignment` with WSN"
    input:
        fasta = temp("_temp_WSN_{number}.fasta")
    output:
        temp("HA_{number}_WSN_prep.pdf"),
        fasta = "HA_{number}_WSN_prep.fasta"
    shell:
        'phydms_prepalignment {input.fasta} {output.fasta} {WSN_REF_HEADER} \
                --minidentity 0.3'

rule phydms_prepalignment_Perth:
    """
    `phydms_prepalignment` QC's the data and makes an alignment using `mafft`.
    """
    message: "Running `phydms_prepalignment` with Perth"
    input:
        fasta = temp("_temp_Perth_{number}.fasta")
    output:
        temp("HA_{number}_Perth_prep.pdf"),
        fasta = "HA_{number}_Perth_prep.fasta"
    shell:
        'phydms_prepalignment {input.fasta} {output.fasta} {PERTH_REF_HEADER} \
                --minidentity 0.3'

rule phydms_prepalignment_hybrid:
    """
    `phydms_prepalignment` QC's the data and makes an alignment using `mafft`.
    """
    message: "Running `phydms_prepalignment` with hybrid"
    input:
        fasta = temp("_temp_hybrid_{number}.fasta")
    output:
        temp("HA_{number}_hybrid_prep.pdf"),
        fasta = "HA_{number}_hybrid_prep.fasta"
    shell:
        'phydms_prepalignment {input.fasta} {output.fasta} {HYBRID_REF_HEADER}\
                --minidentity 0.3'

# Clean up the `phydms_prepalignment` files & remove DMS ref (next 3 rules)
rule phydms_prepalignment_cleanup_WSN:
    """
    `phydms_prepalignment` does not automatically remove the DMS reference from
    the final alignment. This funtion removes the WSN reference and adds an
    ID to each sequence.
    """
    message: "Cleaning up alignment files from `phydms_prepalignment` with WSN"
    input:
        temp = "_temp_WSN_{number}.fasta",
        phydms_fasta = "HA_{number}_WSN_prep.fasta"
    output:
        fasta = "aligned/HA_{number}_WSN_align.fasta"
    params:
        number = "{number}"
    run:
        finalSeqs = []
        for seq in SeqIO.parse(open(input.phydms_fasta), 'fasta'):
            if seq.id == WSN_REF_HEADER:
                pass
            else:
                HA = "HA_{0}".format(params.number)
                seq.description = "{0}_{1}".format(seq.description, HA)
                seq.id = seq.description
                finalSeqs.append(seq)
        with open(output.fasta, "w") as output_handle:
            SeqIO.write(finalSeqs, output_handle, "fasta")
        os.remove(input.temp)
        os.remove(input.phydms_fasta)

rule phydms_prepalignment_cleanup_Perth:
    """
    `phydms_prepalignment` does not automatically remove the DMS reference from
    the final alignment. This funtion removes the Perth reference and adds an
    ID to each sequence.
    """
    message: "Cleaning up alignment files from `phydms_prepalignment` w/ Perth"
    input:
        temp = "_temp_Perth_{number}.fasta",
        phydms_fasta = "HA_{number}_Perth_prep.fasta"
    output:
        fasta = "aligned/HA_{number}_Perth_align.fasta"
    params:
        number = "{number}"
    run:
        finalSeqs = []
        for seq in SeqIO.parse(open(input.phydms_fasta), 'fasta'):
            if seq.id == PERTH_REF_HEADER:
                pass
            else:
                HA = "HA_{0}".format(params.number)
                seq.description = "{0}_{1}".format(seq.description, HA)
                seq.id = seq.description
                finalSeqs.append(seq)
        with open(output.fasta, "w") as output_handle:
            SeqIO.write(finalSeqs, output_handle, "fasta")
        os.remove(input.temp)
        os.remove(input.phydms_fasta)

rule phydms_prepalignment_cleanup_hybrid:
    """
    `phydms_prepalignment` does not automatically remove the DMS reference from
    the final alignment. This funtion removes the hybrid reference and adds an
    ID to each sequence.
    """
    message: "Cleaning up alignment files from `phydms_prepalignment` w/hybrid"
    input:
        temp = "_temp_hybrid_{number}.fasta",
        phydms_fasta = "HA_{number}_hybrid_prep.fasta"
    output:
        fasta = "aligned/HA_{number}_hybrid_align.fasta"
    params:
        number = "{number}"
    run:
        finalSeqs = []
        for seq in SeqIO.parse(open(input.phydms_fasta), 'fasta'):
            if seq.id == HYBRID_REF_HEADER:
                pass
            else:
                HA = "HA_{0}".format(params.number)
                seq.description = "{0}_{1}".format(seq.description, HA)
                seq.id = seq.description
                finalSeqs.append(seq)
        with open(output.fasta, "w") as output_handle:
            SeqIO.write(finalSeqs, output_handle, "fasta")
        os.remove(input.temp)
        os.remove(input.phydms_fasta)

# Create a list of sequences shared between all three alignments (next 1 rule)
rule create_shared_seq_list:
    """
    This function creates a list of sequences which can be aligned to *all*
    three references.
    """
    message: "Create list of shared sequences"
    input:
        fastas = expand("aligned/HA_{number}_{strain}_align.fasta",
                        number=NUMBERS, strain=STRAINS)
    output:
        shared = "shared/shared_seqs.csv"
    run:
        final = []
        for fasta in input.fastas:
            final.extend([x.id for x in SeqIO.parse(fasta, "fasta")])
        c = Counter(final)
        final = [x for x in c.keys() if c[x] == len(STRAINS)]
        final = pd.DataFrame({"seq_id": final})
        final["HA_subtype"] = [x.split("_")[-1] for x in final["seq_id"]]
        final.to_csv(output.shared, index=False)

# Create the alignments with only the shared sequences (next 1 rule)
rule create_shared_seq_alignments:
    """
    This function subsets the alignments so they only contain the shared
    sequences. This means that the "random seed 1" for WSN will contain the
    same sequences as the "random seed 1" for the Perth sequences.
    """
    message: "Create alignments with shared sequences"
    input:
        fasta = "aligned/HA_{number}_{strain}_align.fasta",
        shared = "shared/shared_seqs.csv"
    output:
        shared = "shared/HA_{number}_{strain}_shared.fasta"
    run:
        final = []
        number = int(os.path.basename(input.fasta).split("_")[1])
        shared = pd.read_csv(input.shared)
        shared = shared[shared["HA_subtype"] == number]["seq_id"].tolist()
        seqs = SeqIO.to_dict(SeqIO.parse(input.fasta, "fasta"))
        final = [seqs[x] for x in seqs.keys() if x in shared]
        with open(output.shared, "w") as output_handle:
            SeqIO.write(final, output_handle, "fasta")

rule create_subsample_list:
    """
    This function creates a list of seq ids for each seed.
    """
    message: "Subsampling shared sequence lists"
    input:
        shared = "shared/shared_seqs.csv",
        required = "references/required_seqs.csv",
        fastas = expand("shared/HA_{number}_{strain}_shared.fasta",
                        number=NUMBERS, strain=STRAINS)
    output:
        small_list = "subsample/seq_list_{seed}.csv"
    params:
        seed = "{seed}"
    run:
        seed = int(params.seed)
        random.seed(seed)
        required = pd.read_csv(input.required)
        df = pd.read_csv(input.shared)
        final = {"seq_id": [], "HA_subtype": []}
        for number in NUMBERS:
            required_seqs = required[required["HA_SUBTYPE"] == "H{0}"
                                     .format(number)]["SEQ_ID"].tolist()
            seq_names = df[df["HA_subtype"] == number]["seq_id"].tolist()
            seq_names.sort()  # put seq names in ABC order
            random.shuffle(seq_names)  # shuffle the seq names
            seq_names = createDateDictionary(seq_names)  # parse out the years
            years = list(seq_names.keys())
            years.sort()
            seq_names = [seq_names[x][0] for x in years]  # pick 1st seq/yr
            random.shuffle(seq_names)  # shuffle the sequences
            seq_names = seq_names[0:5]  # pick only 5
            seq_names.extend([x for x in required_seqs if x not in seq_names])
            final["seq_id"].extend([x for x in seq_names])
            final["HA_subtype"].extend([number for x in range(len(seq_names))])
        final = pd.DataFrame(final)
        final.to_csv(output.small_list, index=None)

rule create_subsample_alignments:
    """
    This function creates the subset alignments (high divergence)
    """
    message: "Creating the subset alignments"
    input:
        seq_list = "subsample/seq_list_{seed}.csv",
        fastas = expand("shared/HA_{number}_{strain}_shared.fasta",
                        number=NUMBERS, strain=STRAINS)
    output:
        fasta = "subsample/HA_{strain}_{level_name}_{seed}.fasta"
    params:
        level_name = "{level_name}",
        strain = "{strain}"
    run:
        seq_list = pd.read_csv(input.seq_list)
        target_HAs = LEVELS[LEVEL_NAMES.index(params.level_name)]
        final = []
        for HA in target_HAs:
            seqs = SeqIO.to_dict(SeqIO.parse("shared/HA_{0}_{1}_shared.fasta"
                                             .format(HA, params.strain),
                                             "fasta"))
            target_seqs = seq_list[seq_list["HA_subtype"]
                                   == HA]["seq_id"].tolist()
            final.extend([seqs[x] for x in target_seqs])
        with open(output.fasta, "w") as output_handle:
            SeqIO.write(final, output_handle, "fasta")

# Create divergence summary file (next 1 rule)
rule calculate_divergence:
    """
    This function calculates the divergence from each sequence in the "high"
    divergence alignments to the reference sequence.
    """
    message: "Summarizing divergence distances"
    input:
        fastas = expand("subsample/HA_{strain}_{level_name}_{seed}.fasta",
                        strain=STRAINS, level_name=LEVEL_NAMES, seed=SEEDS)
    output:
        divergences = "subsample/divergence_distances.csv"
    run:
        refs = {"WSN": "cds_ABF21278_A/Wilson-Smith/1933_1933//_HA_HA_1",
                "Perth": "cds_AHX37629_A/Perth/16/2009_2009/04/07_HA_HA_3"}
        df = {"seq_id": [], "divergence": [], "reference": [], "seed": [],
              "alignment_ref": []}
        for fasta in input.fastas:
            strain = os.path.basename(fasta).split("_")[1]
            seed = os.path.basename(fasta).split("_")[-1].split(".")[0]
            seqs = SeqIO.to_dict(SeqIO.parse(fasta, "fasta"))
            for ref in refs.keys():
                if refs[ref] in list(seqs.keys()):
                    ref_aa = translate_with_gaps(seqs[refs[ref]].seq)
                    for seq in seqs.keys():
                        query_aa = translate_with_gaps(str(seqs[seq].seq))
                        assert len(query_aa) == len(ref_aa)
                        divergence = [1 if query_aa[x] == ref_aa[x] else 0 for
                                      x in range(len(ref_aa))]
                        divergence = 1 - (sum(divergence)/len(divergence))
                        df["seq_id"].append(seq)
                        df["divergence"].append(divergence)
                        df["reference"].append(ref)
                        df["seed"].append(seed)
                        df["alignment_ref"].append(strain)
        df = pd.DataFrame(df)
        df.to_csv(output.divergences, index=False)
