"""
Pipeline for prepping HA sequences for `phydms`

SKH 20171217
"""

from Bio import SeqIO
import re
import random
import os
import pandas as pd
import glob
import scipy
from pymodules.utils import *
from collections import Counter

### Set up for translation and pairwise
# codon to index, add codon `---`
max_codon_index = (max(list(constants.CODON_TO_INDEX.values())))
if "---" not in list(constants.CODON_TO_INDEX.keys()):
    constants.CODON_TO_INDEX["---"] = max_codon_index + 1
# index to AA, add AA `-`
max_AA_index = max(list(constants.INDEX_TO_AA.keys()))
if "-" not in list(constants.INDEX_TO_AA.values()):
    constants.INDEX_TO_AA[max_AA_index+1] = "-"
# condon to AA, add mapping of `---` to `-`
constants.CODON_TO_AA = scipy.append(constants.CODON_TO_AA, [[max_AA_index+1]])

# Globals ---------------------------------------------------------------------

# HA subtypes to include in the analysis
NUMBERS = [x for x in range(1,19) if x not in [12,15,17,18]]

# reference sequence names and headers
WSN_REF = "references/WSN_HA_reference.fasta"
WSN_REF_HEADER = "Reference_WSN_HA_coding_sequence_noStart_noStop"
PERTH_REF = "references/Perth_HA_reference.fasta"
PERTH_REF_HEADER = "Reference_Perth2009_HA_coding_sequence_noStop"
HYBRID_REF = "references/WSN_hybrid_reference.fasta"
HYBRID_REF_HEADER = "WSN_hybrid_nt"

# Reference strains
STRAINS = ["WSN", "Perth", "hybrid"]

# Divergence levels for the subsamples
LEVELS = ["low", "intermediate"]
WSN_LEVELS = [[1,2,5,6], [1,2,5,6,8,9,11,13,16]]
PERTH_LEVELS = [[3,4,7,10,14], [3,4,7,8,9,10,11,13,14,16]]

# Number of subsampled alignments
SEEDS = range(2)
# Rules -----------------------------------------------------------------------

rule all:
    input:
        expand("subsample/HA_{strain}_high_{seed}.fasta",strain=STRAINS,seed=SEEDS),
        expand("subsample/HA_WSN_{level}_{seed}.fasta",level=LEVELS,seed=SEEDS),
        expand("subsample/HA_Perth_{level}_{seed}.fasta",level=LEVELS,seed=SEEDS),
        "subsample/divergence_distances.csv"


## Add in each reference sequence to each set of HA sequences (next 3 rules)
rule add_in_WSN:
    """
    `phydms_prepalignment` requires the DMS reference sequence to be present in
    the `inseqs` file. This function adds in the WSN reference from the Doud DMS.
    """
    message: "Add in WSN reference to the files"
    input:
        fasta = "raw/all_H{number}.fasta"
    output:
        temp_file = "_temp_WSN_{number}.fasta"
    shell:
        'cat {input.fasta} {WSN_REF} > {output.temp_file}'

rule add_in_Perth:
    """
    `phydms_prepalignment` requires the DMS reference sequence to be present in
    the `inseqs` file. This function adds in the Perth reference from the Lee DMS.
    """
    message: "Add in Perth reference to the files"
    input:
        fasta = "raw/all_H{number}.fasta"
    output:
        temp_file = "_temp_Perth_{number}.fasta"
    shell:
        'cat {input.fasta} {PERTH_REF} > {output.temp_file}'

rule add_in_hybrid:
    """
    `phydms_prepalignment` requires the DMS reference sequence to be present in
    the `inseqs` file. This function adds in the "hybrid" sequence for
    analysis with the average preferences.
    """
    message: "Add in hybrid reference to the files"
    input:
        fasta = "raw/all_H{number}.fasta"
    output:
        temp_file = "_temp_hybrid_{number}.fasta"
    shell:
        'cat {input.fasta} {HYBRID_REF} > {output.temp_file}'

## Run `phydms_prepalignment` for each of the set of HA sequences (next 3 rules)
rule phydms_prepalignment_WSN:
    """
    `phydms_prepalignment` QC's the data and makes an alignment using `mafft`.
    """
    message: "Running `phydms_prepalignment` with WSN"
    input:
        fasta = temp("_temp_WSN_{number}.fasta")
    output:
        temp("HA_{number}_WSN_prep.pdf"),
        fasta = "HA_{number}_WSN_prep.fasta"
    shell:
        'phydms_prepalignment {input.fasta} {output.fasta} {WSN_REF_HEADER} --minidentity 0.3'

rule phydms_prepalignment_Perth:
    """
    `phydms_prepalignment` QC's the data and makes an alignment using `mafft`.
    """
    message: "Running `phydms_prepalignment` with Perth"
    input:
        fasta = temp("_temp_Perth_{number}.fasta")
    output:
        temp("HA_{number}_Perth_prep.pdf"),
        fasta = "HA_{number}_Perth_prep.fasta"
    shell:
        'phydms_prepalignment {input.fasta} {output.fasta} {PERTH_REF_HEADER} --minidentity 0.3'

rule phydms_prepalignment_hybrid:
    """
    `phydms_prepalignment` QC's the data and makes an alignment using `mafft`.
    """
    message: "Running `phydms_prepalignment` with hybrid"
    input:
        fasta = temp("_temp_hybrid_{number}.fasta")
    output:
        temp("HA_{number}_hybrid_prep.pdf"),
        fasta = "HA_{number}_hybrid_prep.fasta"
    shell:
        'phydms_prepalignment {input.fasta} {output.fasta} {HYBRID_REF_HEADER} --minidentity 0.3'

## Clean up the `phydms_prepalignment` files to remove DMS reference (next 3 rules)
rule phydms_prepalignment_cleanup_WSN:
    """
    `phydms_prepalignment` does not automatically remove the DMS reference from
    the final alignment. This funtion removes the WSN reference and adds an
    ID to each sequence.
    """
    message: "Cleaning up alignment files from `phydms_prepalignment` with WSN"
    input:
        temp = "_temp_WSN_{number}.fasta",
        phydms_fasta = "HA_{number}_WSN_prep.fasta"
    output:
        fasta = "aligned/HA_{number}_WSN_align.fasta"
    params:
        number = "{number}"
    run:
        finalSeqs = []
        for seq in SeqIO.parse(open(input.phydms_fasta),'fasta'):
            if seq.id == WSN_REF_HEADER:
                pass
            else:
                HA = "HA_{0}".format(params.number)
                seq.description = "{0}_{1}".format(seq.description,HA)
                seq.id = seq.description
                finalSeqs.append(seq)
        with open(output.fasta, "w") as output_handle:
            SeqIO.write(finalSeqs, output_handle, "fasta")
        os.remove(input.temp)
        os.remove(input.phydms_fasta)

rule phydms_prepalignment_cleanup_Perth:
    """
    `phydms_prepalignment` does not automatically remove the DMS reference from
    the final alignment. This funtion removes the Perth reference and adds an
    ID to each sequence.
    """
    message: "Cleaning up alignment files from `phydms_prepalignment` with Perth"
    input:
        temp = "_temp_Perth_{number}.fasta",
        phydms_fasta = "HA_{number}_Perth_prep.fasta"
    output:
        fasta = "aligned/HA_{number}_Perth_align.fasta"
    params:
        number = "{number}"
    run:
        finalSeqs = []
        for seq in SeqIO.parse(open(input.phydms_fasta),'fasta'):
            if seq.id == PERTH_REF_HEADER:
                pass
            else:
                HA = "HA_{0}".format(params.number)
                seq.description = "{0}_{1}".format(seq.description,HA)
                seq.id = seq.description
                finalSeqs.append(seq)
        with open(output.fasta, "w") as output_handle:
            SeqIO.write(finalSeqs, output_handle, "fasta")
        os.remove(input.temp)
        os.remove(input.phydms_fasta)

rule phydms_prepalignment_cleanup_hybrid:
    """
    `phydms_prepalignment` does not automatically remove the DMS reference from
    the final alignment. This funtion removes the hybrid reference and adds an
    ID to each sequence.
    """
    message: "Cleaning up alignment files from `phydms_prepalignment` with hybrid"
    input:
        temp = "_temp_hybrid_{number}.fasta",
        phydms_fasta = "HA_{number}_hybrid_prep.fasta"
    output:
        fasta = "aligned/HA_{number}_hybrid_align.fasta"
    params:
        number = "{number}"
    run:
        finalSeqs = []
        for seq in SeqIO.parse(open(input.phydms_fasta),'fasta'):
            if seq.id == HYBRID_REF_HEADER:
                pass
            else:
                HA = "HA_{0}".format(params.number)
                seq.description = "{0}_{1}".format(seq.description,HA)
                seq.id = seq.description
                finalSeqs.append(seq)
        with open(output.fasta, "w") as output_handle:
            SeqIO.write(finalSeqs, output_handle, "fasta")
        os.remove(input.temp)
        os.remove(input.phydms_fasta)

## Create a list of sequences shared between all three alignments (next 1 rule)
rule create_shared_seq_list:
    """
    This function creates a list of sequences which can be aligned to *all*
    three references.
    """
    message: "Create list of shared sequences"
    input:
        fastas = expand("aligned/HA_{number}_{strain}_align.fasta", number=NUMBERS,strain=STRAINS)
    output:
        shared = "shared/shared_seqs.csv"
    run:
        final = []
        for fasta in input.fastas:
            final.extend([x.id for x in SeqIO.parse(fasta, "fasta")])
        c = Counter(final)
        final = [x for x in c.keys() if c[x] == 3]
        final = pd.DataFrame({"seq_id":final})
        final["HA_subtype"] = [x.split("_")[-1] for x in final["seq_id"]]
        final.to_csv(output.shared, index=False)

# Create the alignments with only the shared sequences (next 1 rule)
rule create_shared_seq_alignments:
    """
    This function subsets the alignments so they only contain the shared sequences.
    This means that the "random seed 1" for WSN will contain the same sequences
    as the "random seed 1" for the Perth sequences.
    """
    message: "Create alignments with shared sequences"
    input:
        fasta = "aligned/HA_{number}_{strain}_align.fasta",
        shared = "shared/shared_seqs.csv"
    output:
        shared = "shared/HA_{number}_{strain}_shared.fasta"
    run:
        final = []
        number = int(os.path.basename(input.fasta).split("_")[1])
        shared = pd.read_csv(input.shared)
        shared = shared[shared["HA_subtype"] == number]["seq_id"].tolist()
        seqs = SeqIO.to_dict(SeqIO.parse(input.fasta, "fasta"))
        final = [seqs[x] for x in seqs.keys() if x in shared]
        with open(output.shared, "w") as output_handle:
            SeqIO.write(final, output_handle, "fasta")

# Create the subsampled alignments to be used by `phydms` (next 3 rules)
rule subsample:
    """
    This function creates an alignment with
        1. All of the target HA subtypes (defined in globals)
        2. A minimum of 5 sequences per HA subtype
        3. At most 1 sequence per year
        4. The sequences in the `required_seqs.csv` reference file
    """
    message: "Subsampling shared sequence alignments"
    input:
        fastas = expand("shared/HA_{number}_{strain}_shared.fasta",number=NUMBERS,strain=STRAINS),
        required = "references/required_seqs.csv"
    output:
        small_alignment = "subsample/HA_{strain}_high_{seed}.fasta"
    run:
        strain = os.path.basename(output.small_alignment).split(".")[0].split("_")
        seed = int(strain[-1])
        strain = strain[1]
        required = pd.read_csv(input.required)
        random.seed(seed)
        final = []

        for number in NUMBERS:
            required_seqs = required[required["HA_SUBTYPE"] == "H{0}".format(number)]["SEQ_ID"].tolist()
            seqs = SeqIO.to_dict(SeqIO.parse("shared/HA_{0}_{1}_shared.fasta".format(number, strain), "fasta"))
            seq_names = [x for x in seqs.keys()]
            seq_names.sort() # put seq names in ABC order
            random.shuffle(seq_names) # shuffle the seq names
            seq_names = createDateDictionary(seq_names) # parse out the years
            years = list(seq_names.keys())
            years.sort()
            seq_names = [seq_names[x][0] for x in years] # pick the first sequence for each year
            random.shuffle(seq_names) # shuffle the sequences
            seq_names = seq_names[0:5] # pick only 5
            seq_names.extend([x for x in required_seqs if x not in seq_names])
            final.extend([seqs[x] for x in seq_names])
        with open(output.small_alignment, "w") as output_handle:
            SeqIO.write(final, output_handle, "fasta")

rule subsample_divergence_level_WSN:
    """
    This function creates alignments for WSN which have varying levels
    of divergence.
    """
    message: "Creating alignments with different divergence levels"
    input:
        fasta = "subsample/HA_WSN_high_{seed}.fasta"
    output:
        fasta = "subsample/HA_WSN_{level}_{seed}.fasta"
    run:
        level = os.path.basename(output.fasta).split("_")[-2]
        assert level in LEVELS
        if level == "low":
            level = WSN_LEVELS[0]
        else:
            level = WSN_LEVELS[1]
        final = [x for x in SeqIO.parse(input.fasta, "fasta") if int(x.id.split("_")[-1]) in level]
        with open(output.fasta, "w") as output_handle:
            SeqIO.write(final, output_handle, "fasta")

rule subsample_divergence_level_Perth:
    """
    This function creates alignments for WSN which have varying levels
    of divergence.
    """
    message: "Creating alignments with different divergence levels"
    input:
        fasta = "subsample/HA_Perth_high_{seed}.fasta"
    output:
        fasta = "subsample/HA_Perth_{level}_{seed}.fasta"
    run:
        level = os.path.basename(output.fasta).split("_")[-2]
        assert level in LEVELS
        if level == "low":
            level = PERTH_LEVELS[0]
        else:
            level = PERTH_LEVELS[1]
        final = [x for x in SeqIO.parse(input.fasta, "fasta") if int(x.id.split("_")[-1]) in level]
        with open(output.fasta, "w") as output_handle:
            SeqIO.write(final, output_handle, "fasta")

## Create final summary file (next 1 rule)
rule calculate_divergence:
    """
    This function calculates the divergence from each sequence in the "high"
    divergence alignments to the reference sequence.
    """
    message: "Summarizing divergence distances"
    input:
        fastas = expand("subsample/HA_{strain}_high_{seed}.fasta", strain=STRAINS, seed=SEEDS)
    output:
        divergences = "subsample/divergence_distances.csv"
    run:
        df = {"seq_id":[], "divergence":[], "reference":[], "seed":[]}
        for fasta in input.fastas:
            if "hybrid" in fasta:
                pass
            else:
                strain = os.path.basename(fasta).split("_")[1]
                if strain == "WSN":
                    ref = "cds_ABF21278_A/Wilson-Smith/1933_1933//_HA_HA_1"
                elif strain == "Perth":
                    ref = "cds_AHX37629_A/Perth/16/2009_2009/04/07_HA_HA_3"
                else:
                    raise ValueError("Wrong parse of strain name")
                seed = os.path.basename(fasta).split(".")[0].split("_")[-1]
                seqs = SeqIO.to_dict(SeqIO.parse(fasta, "fasta"))
                ref_aa = translate_with_gaps(seqs[ref].seq)
                for seq in seqs.keys():
                    query_aa = translate_with_gaps(str(seqs[seq].seq))
                    assert len(query_aa) == len(ref_aa)
                    divergence = [1 if query_aa[x] == ref_aa[x] else 0 for x in range(len(ref_aa))]
                    divergence = 1 - (sum(divergence)/len(divergence))
                    df["seq_id"].append(seq)
                    df["divergence"].append(divergence)
                    df["reference"].append(strain)
                    df["seed"].append(seed)
        df = pd.DataFrame(df)
        df.to_csv(output.divergences, index=False)
